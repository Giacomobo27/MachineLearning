{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tq5jQApIUnNL"
      },
      "source": [
        "# COMP47590: Advanced Machine Learning\n",
        "# Assignment 1: Benchmarking Esemble Methods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zYvByK3UnNN"
      },
      "source": [
        "Name(s):  jin giacomo\n",
        "\n",
        "Student Number(s): 24216191"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1ImHL16UnNO"
      },
      "source": [
        "## Import Packages Etc"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install aeon"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TMKtpP20hecj",
        "outputId": "3edfa73c-7371-4486-837b-c21263e8e25a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: aeon in /usr/local/lib/python3.11/dist-packages (1.0.0)\n",
            "Requirement already satisfied: deprecated>=1.2.13 in /usr/local/lib/python3.11/dist-packages (from aeon) (1.2.18)\n",
            "Requirement already satisfied: numba<0.61.0,>=0.55 in /usr/local/lib/python3.11/dist-packages (from aeon) (0.60.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.21.0 in /usr/local/lib/python3.11/dist-packages (from aeon) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from aeon) (24.2)\n",
            "Requirement already satisfied: pandas<2.3.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from aeon) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn<1.6.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from aeon) (1.5.2)\n",
            "Requirement already satisfied: scipy<1.15.0,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from aeon) (1.14.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from aeon) (4.12.2)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from deprecated>=1.2.13->aeon) (1.17.2)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba<0.61.0,>=0.55->aeon) (0.43.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<2.3.0,>=2.0.0->aeon) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<2.3.0,>=2.0.0->aeon) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<2.3.0,>=2.0.0->aeon) (2025.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<1.6.0,>=1.0.0->aeon) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<1.6.0,>=1.0.0->aeon) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<2.3.0,>=2.0.0->aeon) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "eN6SAUFDUnNO"
      },
      "outputs": [],
      "source": [
        "import io\n",
        "import time\n",
        "import pickle\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from matplotlib import pyplot\n",
        "%matplotlib inline\n",
        "from random import randint\n",
        "import math\n",
        "import sklearn\n",
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "\n",
        "from sklearn.utils.validation import check_X_y\n",
        "from sklearn.model_selection import ParameterSampler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from scipy.stats import mode\n",
        "\n",
        "import sklearn.model_selection\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn import metrics\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.model_selection import train_test_split, cross_validate, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import seaborn as sns # nicer plotting functionlity\n",
        "\n",
        "\n",
        "import aeon # time series classification package with nice benchmarking functions\n",
        "import aeon.benchmarking\n",
        "import aeon.benchmarking.stats\n",
        "import aeon.visualisation\n",
        "import matplotlib # core plotting functioanlity\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import cross_val_score # Import the cross_val_score function\n",
        "\n",
        "\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wIL0nFPgUnNP"
      },
      "source": [
        "## Task 1: Define HyperParamClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjdlJdDTUnNP"
      },
      "source": [
        "HyperParamClassifier class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "foSfbZSfUnNP"
      },
      "outputs": [],
      "source": [
        "# Create a new classifier which is based on the sckit-learn BaseEstimator and ClassifierMixin classes\n",
        "class HyperParamClassifier(BaseEstimator, ClassifierMixin):\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    base_estimator KNeighborsClassifier()\n",
        "\n",
        "    param_grid :\n",
        "        Dictionary with parameters names (string) as keys and lists of parameter settings to try as values,\n",
        "\n",
        "    n_estimators : int, default=5\n",
        "        Number of models in the ensemble.\n",
        "\n",
        "    Attributes\n",
        "    ----------\n",
        "    models : list\n",
        "        Trained KNN models with different hyperparameters.\n",
        "\n",
        "    Notes\n",
        "    -----\n",
        "    - Uses voting to combine predictions.\n",
        "\n",
        "    Example\n",
        "    -------\n",
        "    >>> from sklearn.neighbors import KNeighborsClassifier\n",
        "    >>> param_grid = {\"n_neighbors\": [3, 5], \"weights\": [\"distance\"], \"metric\": [\"euclidean\", \"manhattan\"]}\n",
        "    >>> model = HyperParamClassifier( param_grid, n_estimators=4)\n",
        "    >>> model.fit(X_train, y_train)\n",
        "    >>> y_pred = model.predict(X_test)\n",
        "    \"\"\"\n",
        "\n",
        "    # Constructor for the classifier object\n",
        "    def __init__(self, param_grid, n_estimators ):\n",
        "        self.models= []\n",
        "        self.param_grid=param_grid\n",
        "        self.n_estimators=n_estimators\n",
        "\n",
        "    # The fit function to train a classifier\n",
        "    def fit(self, X, y):\n",
        "        \"\"\"Build a HyperParamClassifier classifier from the training set (X, y).\n",
        "        Parameters\n",
        "        X : array-like, shape = [n_samples, n_features]\n",
        "            The training input samples.\n",
        "        y : array-like, shape = [n_samples]\n",
        "            The target values (class labels) as integers or strings.\n",
        "        Returns\n",
        "        self : object\n",
        "        \"\"\"\n",
        "        if not isinstance(X, (np.ndarray, list)):\n",
        "            raise ValueError(\"X should be a NumPy array or a list of numerical values.\")\n",
        "        if not isinstance(y, (np.ndarray, list)):\n",
        "            raise ValueError(\"y should be a NumPy array or a list.\")\n",
        "        X = np.array(X) if isinstance(X, list) else X\n",
        "        y = np.array(y) if isinstance(y, list) else y\n",
        "        if X.ndim != 2:\n",
        "            raise ValueError(f\"X must be a 2D array (samples, features). Found {X.ndim}D instead.\")\n",
        "        if y.ndim != 1:\n",
        "            raise ValueError(f\"y must be a 1D array (labels). Found {y.ndim}D instead.\")\n",
        "\n",
        "        if len(X) != len(y):\n",
        "            raise ValueError(f\"Mismatch: X has {len(X)} samples, but y has {len(y)}.\")\n",
        "\n",
        "        self.classes_ = np.unique(y)\n",
        "        self.models.clear()\n",
        "\n",
        "       # random parameters\n",
        "        sampled_params = list(ParameterSampler(self.param_grid, n_iter=self.n_estimators, random_state=42))\n",
        "\n",
        "        for param_set in sampled_params:\n",
        "            model = KNeighborsClassifier(**param_set)\n",
        "            model.fit(X, y)\n",
        "            self.models.append(model)\n",
        "        return self\n",
        "\n",
        "    # The predict function to make a set of predictions for a set of query instances\n",
        "    def predict(self, X):\n",
        "        if not self.models:\n",
        "            raise ValueError(\"The model has not been trained. Call fit() first.\")\n",
        "        if not isinstance(X, (np.ndarray, list)):\n",
        "            raise ValueError(\"X should be a NumPy array or a list of numerical values.\")\n",
        "        X = np.array(X) if isinstance(X, list) else X  # Convert list to NumPy array\n",
        "        if X.ndim != 2:\n",
        "            raise ValueError(f\"X must be a 2D array (samples, features). Found {X.ndim}D instead.\")\n",
        "        predictions = np.array([model.predict(X) for model in self.models])  # Shape: (n_estimators, n_samples)\n",
        "        final_predictions = mode(predictions, axis=0)[0].flatten()  # Most common class per sample\n",
        "        return final_predictions\n",
        "\n",
        "    # The predict function to make a set of predictions for a set of query instances\n",
        "    def predict_proba(self, X):\n",
        "        if not self.models:\n",
        "            raise ValueError(\"The model has not been trained. Call fit() first.\")\n",
        "        if not isinstance(X, (np.ndarray, list)):\n",
        "            raise ValueError(\"X should be a NumPy array or a list of numerical values.\")\n",
        "        X = np.array(X) if isinstance(X, list) else X  # Convert list to NumPy array\n",
        "        if X.ndim != 2:\n",
        "            raise ValueError(f\"X must be a 2D array (samples, features). Found {X.ndim}D instead.\")\n",
        "        probas = np.array([model.predict_proba(X) for model in self.models])\n",
        "        final_probas = np.mean(probas, axis=0)  # Shape: (n_samples, n_classes)\n",
        "        return final_probas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uye7m2InUnNQ"
      },
      "source": [
        "## Test the HyperParamClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76lAJJF5UnNQ"
      },
      "source": [
        "Perform a simple test using the HyperParamClassifier on the Iris dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "NRI8pog4UnNQ",
        "outputId": "3b18e0fb-6b20-4a24-8827-05ed71d1f01f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        50\n",
            "           1       1.00      1.00      1.00        50\n",
            "           2       1.00      1.00      1.00        50\n",
            "\n",
            "    accuracy                           1.00       150\n",
            "   macro avg       1.00      1.00      1.00       150\n",
            "weighted avg       1.00      1.00      1.00       150\n",
            "\n",
            "Confusion Matrix\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predicted   0   1   2  All\n",
              "True                      \n",
              "0          50   0   0   50\n",
              "1           0  50   0   50\n",
              "2           0   0  50   50\n",
              "All        50  50  50  150"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bc62268d-8d93-4bba-b808-7d45afae5391\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Predicted</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>All</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>True</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>50</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>50</td>\n",
              "      <td>0</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>50</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>All</th>\n",
              "      <td>50</td>\n",
              "      <td>50</td>\n",
              "      <td>50</td>\n",
              "      <td>150</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bc62268d-8d93-4bba-b808-7d45afae5391')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-bc62268d-8d93-4bba-b808-7d45afae5391 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-bc62268d-8d93-4bba-b808-7d45afae5391');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a5c96da5-de20-43ae-aa55-412542b4858d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a5c96da5-de20-43ae-aa55-412542b4858d')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a5c96da5-de20-43ae-aa55-412542b4858d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(pd\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"True\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          1,\n          \"All\",\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 0,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 28,\n        \"min\": 0,\n        \"max\": 50,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          50\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 1,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 28,\n        \"min\": 0,\n        \"max\": 50,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          50,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 2,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 28,\n        \"min\": 0,\n        \"max\": 50,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          50,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"All\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 50,\n        \"min\": 50,\n        \"max\": 150,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          150,\n          50\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from sklearn.datasets import load_iris\n",
        "iris = load_iris()\n",
        "param_grid: dict = {\n",
        "    'n_neighbors': list(range(3, 6, 2)),  # Generates [3, 5]\n",
        "    'weights': ['distance'],  # Only one option, but still a valid parameter\n",
        "    'metric': ['euclidean', 'manhattan']  # Two distance metrics to test\n",
        "}\n",
        "clf = HyperParamClassifier(param_grid,3)\n",
        "clf.fit(iris.data, iris.target)\n",
        "y_pred = clf.predict(iris.data)\n",
        "print(metrics.classification_report(iris.target, y_pred))\n",
        "print(\"Confusion Matrix\")\n",
        "display(pd.crosstab(np.array(iris.target), y_pred, rownames=['True'], colnames=['Predicted'], margins=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvy0PDzfUnNR"
      },
      "source": [
        "Perform a cross validation experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "0GbEIYRaUnNR",
        "outputId": "784a4815-db4a-4874-da9b-3d51e901d0f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        50\n",
            "           1       1.00      1.00      1.00        50\n",
            "           2       1.00      1.00      1.00        50\n",
            "\n",
            "    accuracy                           1.00       150\n",
            "   macro avg       1.00      1.00      1.00       150\n",
            "weighted avg       1.00      1.00      1.00       150\n",
            "\n",
            "Confusion Matrix\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predicted   0   1   2  All\n",
              "True                      \n",
              "0          50   0   0   50\n",
              "1           0  50   0   50\n",
              "2           0   0  50   50\n",
              "All        50  50  50  150"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a166bc54-d907-45dc-b06f-3e1a6800961e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Predicted</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>All</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>True</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>50</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>50</td>\n",
              "      <td>0</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>50</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>All</th>\n",
              "      <td>50</td>\n",
              "      <td>50</td>\n",
              "      <td>50</td>\n",
              "      <td>150</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a166bc54-d907-45dc-b06f-3e1a6800961e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a166bc54-d907-45dc-b06f-3e1a6800961e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a166bc54-d907-45dc-b06f-3e1a6800961e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0e97c2a8-620d-4aaf-9d39-7dd07c328dd0\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0e97c2a8-620d-4aaf-9d39-7dd07c328dd0')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0e97c2a8-620d-4aaf-9d39-7dd07c328dd0 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"print(\\\"Mean accuracy:\\\", np\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"True\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          1,\n          \"All\",\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 0,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 28,\n        \"min\": 0,\n        \"max\": 50,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          50\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 1,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 28,\n        \"min\": 0,\n        \"max\": 50,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          50,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 2,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 28,\n        \"min\": 0,\n        \"max\": 50,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          50,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"All\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 50,\n        \"min\": 50,\n        \"max\": 150,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          150,\n          50\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-validation scores: [1.         0.93333333 1.         1.         0.86666667 0.93333333\n",
            " 0.93333333 1.         1.         1.        ]\n",
            "Mean accuracy: 0.9666666666666668 +/- 0.04472135954999579\n"
          ]
        }
      ],
      "source": [
        "param_grid: dict = {\n",
        "    'n_neighbors': list(range(3, 6, 2)),  # Generates [3, 5]\n",
        "    'weights': ['distance'],  # Only one option, but still a valid parameter\n",
        "    'metric': ['euclidean', 'manhattan']  # Two distance metrics to test\n",
        "}\n",
        "clf = HyperParamClassifier(param_grid,3)\n",
        "scores = cross_val_score(clf, iris.data, iris.target, cv=10)\n",
        "\n",
        "\n",
        "clf.fit(iris.data, iris.target)\n",
        "y_pred = clf.predict(iris.data)\n",
        "print(metrics.classification_report(iris.target, y_pred))\n",
        "print(\"Confusion Matrix\")\n",
        "display(pd.crosstab(np.array(iris.target), y_pred, rownames=['True'], colnames=['Predicted'], margins=True))\n",
        "\n",
        "print(\"Cross-validation scores:\", scores)\n",
        "print(\"Mean accuracy:\", np.mean(scores), \"+/-\", np.std(scores))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ftcq1QdUnNS"
      },
      "source": [
        "## Task 2: Design the Evaluation Experiment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fVFMdmIjUnNS"
      },
      "source": [
        "Describe datasets and expeimental apporach and setup infrastructure for experimentation."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris,load_breast_cancer, load_digits, load_wine, fetch_openml, fetch_covtype"
      ],
      "metadata": {
        "id": "EeH7JcD-XyAz"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup Datasets"
      ],
      "metadata": {
        "id": "pW3TzclFYH0t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import resample\n",
        "from sklearn.datasets import fetch_covtype\n",
        "\n",
        "datasets = dict()  # Ensures compatibility with your loop\n",
        "\n",
        "# Function to structure datasets in the expected format\n",
        "def prepare_dataset(name, dataset, target_feature=\"target\"):\n",
        "    return {\n",
        "        \"target_feature\": target_feature,\n",
        "        \"num_classes\": len(set(dataset.target)),\n",
        "        \"classes\": {i: str(i) for i in set(dataset.target)},\n",
        "        \"data\": dataset.data,\n",
        "        \"target\": dataset.target\n",
        "    }\n",
        "\n",
        "# Load built-in Scikit-Learn datasets and format them correctly\n",
        "datasets[\"Breast Cancer\"] = prepare_dataset(\"Breast Cancer\", load_breast_cancer())\n",
        "datasets[\"Digits\"] = prepare_dataset(\"Digits\", load_digits())\n",
        "datasets[\"Wine\"] = prepare_dataset(\"Wine\", load_wine())\n",
        "datasets[\"Iris\"] = prepare_dataset(\"Iris\", load_iris())\n",
        "\n",
        "\n",
        "# Load and Downsample \"Forest Cover Type\" (from 581,012 â†’ 2,000 samples)\n",
        "print(\"Loading and downsampling 'Forest Cover Type' dataset...\")\n",
        "covtype_dataset = fetch_covtype()\n",
        "X_covtype, y_covtype = covtype_dataset.data, covtype_dataset.target\n",
        "\n",
        "X_covtype_small, y_covtype_small = resample(X_covtype, y_covtype, n_samples=2000, random_state=42)\n",
        "\n",
        "\n",
        "datasets[\"Forest Cover Type\"] = {\n",
        "    \"target_feature\": \"target\",\n",
        "    \"num_classes\": len(set(y_covtype_small)),\n",
        "    \"classes\": {i: str(i) for i in set(y_covtype_small)},\n",
        "    \"data\": X_covtype_small,\n",
        "    \"target\": y_covtype_small\n",
        "}\n",
        "\n",
        "\n",
        "for dataset_name, dataset_details in datasets.items():\n",
        "    print(f\"{dataset_name}: Keys -> {dataset_details.keys()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yLrwHrVFjZjI",
        "outputId": "4133ea14-b575-48f7-df02-04f617dbf97d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading and downsampling 'Forest Cover Type' dataset...\n",
            "Breast Cancer: Keys -> dict_keys(['target_feature', 'num_classes', 'classes', 'data', 'target'])\n",
            "Digits: Keys -> dict_keys(['target_feature', 'num_classes', 'classes', 'data', 'target'])\n",
            "Wine: Keys -> dict_keys(['target_feature', 'num_classes', 'classes', 'data', 'target'])\n",
            "Iris: Keys -> dict_keys(['target_feature', 'num_classes', 'classes', 'data', 'target'])\n",
            "Forest Cover Type: Keys -> dict_keys(['target_feature', 'num_classes', 'classes', 'data', 'target'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup models to compare"
      ],
      "metadata": {
        "id": "Pz8j2pX3YSeZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#DecisionTree\n",
        "modelsBench = dict()\n",
        "model_details = dict()\n",
        "model_details['base_model'] = sklearn.tree.DecisionTreeClassifier()\n",
        "model_details['param_grid'] ={'criterion': ['entropy'],\n",
        "                              'max_depth': [12],\n",
        "                              'min_samples_split': [50]}\n",
        "modelsBench['decision_tree'] = model_details"
      ],
      "metadata": {
        "id": "T0Su2z-vX9qE"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Naive Bayes\n",
        "model_details = dict()\n",
        "model_details['base_model'] = sklearn.naive_bayes.GaussianNB()\n",
        "model_details['param_grid'] = {\n",
        "    'var_smoothing': [1e-6]\n",
        "}\n",
        "modelsBench['naive_bayes'] = model_details"
      ],
      "metadata": {
        "id": "BkIO-Y06ZYfx"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#SingleKNN\n",
        "model_details = dict()\n",
        "model_details['base_model'] = KNeighborsClassifier()\n",
        "model_details['param_grid'] = {\n",
        "    'n_neighbors':[ 3],\n",
        "    'weights': ['distance'],\n",
        "    'metric': ['euclidean']\n",
        "}\n",
        "modelsBench['knn'] = model_details"
      ],
      "metadata": {
        "id": "X3-N3MFLZLOH"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#RandomForest\n",
        "model_details = dict()\n",
        "model_details['base_model'] = sklearn.ensemble.RandomForestClassifier(min_samples_split=200)\n",
        "model_details['param_grid'] = {'n_estimators': [450],\n",
        "                               'max_features': list(range(4, 9, 4))} # either 4 or 8 is the best one\n",
        "modelsBench['random_forest'] = model_details"
      ],
      "metadata": {
        "id": "s78PNINzaMMz"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "i gave each model the best parameters found in the previous assignments( skipped grid search on them to alleviate computational load on my budget laptop)"
      ],
      "metadata": {
        "id": "LphBk7CXaqom"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#HyperParamEnsemble\n",
        "model_details = dict()\n",
        "param_grid: dict = {\n",
        "    'n_neighbors': list(range(3, 6, 2)),  # Generates [3, 5]\n",
        "    'weights': ['distance'],  # Only one option, but still a valid parameter\n",
        "    'metric': ['euclidean', 'manhattan']  # Two distance metrics to test\n",
        "}\n",
        "model_details['base_model'] = HyperParamClassifier(param_grid,3)\n",
        "model_details['param_grid'] = param_grid\n",
        "modelsBench['hyper'] = model_details\n",
        "\n"
      ],
      "metadata": {
        "id": "_Kc6ng0nbm93"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z11K1rmcUnNS"
      },
      "source": [
        "## Task 3: Execute Evalution Experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJT4qkHCUnNS",
        "outputId": "e2227604-d220-4321-c838-0e7f8916250f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Breast Cancer\n",
            "\tdecision_tree\n",
            "\t\tPerforming grid search\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "\t\tBest Parameters: {'criterion': 'entropy', 'max_depth': 12, 'min_samples_split': 50}\n",
            "\t\tPerforming final cross validation\n",
            "\t\t0.9165700483091788 +/- 0.03981628913741204\n",
            "\t\tTraining Best Model on Full Training Set\n",
            "\t\tMaking final predictions on the full dataset\n",
            "\t\tFinal Accuracy on Full Dataset: 0.9123\n",
            "\tnaive_bayes\n",
            "\t\tPerforming grid search\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "\t\tBest Parameters: {'var_smoothing': 1e-06}\n",
            "\t\tPerforming final cross validation\n",
            "\t\t0.9141545893719808 +/- 0.04900467947522281\n",
            "\t\tTraining Best Model on Full Training Set\n",
            "\t\tMaking final predictions on the full dataset\n",
            "\t\tFinal Accuracy on Full Dataset: 0.9561\n",
            "\tknn\n",
            "\t\tPerforming grid search\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "\t\tBest Parameters: {'metric': 'euclidean', 'n_neighbors': 3, 'weights': 'distance'}\n",
            "\t\tPerforming final cross validation\n",
            "\t\t0.9318357487922706 +/- 0.04767675412449899\n",
            "\t\tTraining Best Model on Full Training Set\n",
            "\t\tMaking final predictions on the full dataset\n",
            "\t\tFinal Accuracy on Full Dataset: 0.9386\n",
            "\trandom_forest\n",
            "\t\tPerforming grid search\n",
            "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
            "\t\tBest Parameters: {'max_features': 8, 'n_estimators': 450}\n",
            "\t\tPerforming final cross validation\n",
            "\t\t0.9141545893719807 +/- 0.03883712460898421\n",
            "\t\tTraining Best Model on Full Training Set\n",
            "\t\tMaking final predictions on the full dataset\n",
            "\t\tFinal Accuracy on Full Dataset: 0.9561\n",
            "\thyper\n",
            "\t\tSkipping Grid Search for HyperParamClassifier\n",
            "\t\t0.9273429951690823 +/- 0.051326632532010245\n",
            "\t\tFitting with HyperParamClassifier\n",
            "\t\tTesting HyperParamClassifier on test set\n",
            "\t\tFinal Accuracy on Full Dataset: 0.9561\n",
            "Digits\n",
            "\tdecision_tree\n",
            "\t\tPerforming grid search\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "\t\tBest Parameters: {'criterion': 'entropy', 'max_depth': 12, 'min_samples_split': 50}\n",
            "\t\tPerforming final cross validation\n",
            "\t\t0.8156031468531468 +/- 0.022977142382685844\n",
            "\t\tTraining Best Model on Full Training Set\n",
            "\t\tMaking final predictions on the full dataset\n",
            "\t\tFinal Accuracy on Full Dataset: 0.8306\n",
            "\tnaive_bayes\n",
            "\t\tPerforming grid search\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "\t\tBest Parameters: {'var_smoothing': 1e-06}\n",
            "\t\tPerforming final cross validation\n",
            "\t\t0.8761217948717949 +/- 0.03919475111465704\n",
            "\t\tTraining Best Model on Full Training Set\n",
            "\t\tMaking final predictions on the full dataset\n",
            "\t\tFinal Accuracy on Full Dataset: 0.8917\n",
            "\tknn\n",
            "\t\tPerforming grid search\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "\t\tBest Parameters: {'metric': 'euclidean', 'n_neighbors': 3, 'weights': 'distance'}\n",
            "\t\tPerforming final cross validation\n",
            "\t\t0.9874757187257188 +/- 0.009212929833587494\n",
            "\t\tTraining Best Model on Full Training Set\n",
            "\t\tMaking final predictions on the full dataset\n",
            "\t\tFinal Accuracy on Full Dataset: 0.9833\n",
            "\trandom_forest\n",
            "\t\tPerforming grid search\n",
            "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
            "\t\tBest Parameters: {'max_features': 4, 'n_estimators': 450}\n",
            "\t\tPerforming final cross validation\n",
            "\t\t0.8872620435120435 +/- 0.02427351517442602\n",
            "\t\tTraining Best Model on Full Training Set\n",
            "\t\tMaking final predictions on the full dataset\n",
            "\t\tFinal Accuracy on Full Dataset: 0.9056\n",
            "\thyper\n",
            "\t\tSkipping Grid Search for HyperParamClassifier\n",
            "\t\t0.9881701631701632 +/- 0.009854110558726824\n",
            "\t\tFitting with HyperParamClassifier\n",
            "\t\tTesting HyperParamClassifier on test set\n",
            "\t\tFinal Accuracy on Full Dataset: 0.9833\n",
            "Wine\n",
            "\tdecision_tree\n",
            "\t\tPerforming grid search\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "\t\tBest Parameters: {'criterion': 'entropy', 'max_depth': 12, 'min_samples_split': 50}\n",
            "\t\tPerforming final cross validation\n",
            "\t\t0.8580952380952382 +/- 0.07913363077272759\n",
            "\t\tTraining Best Model on Full Training Set\n",
            "\t\tMaking final predictions on the full dataset\n",
            "\t\tFinal Accuracy on Full Dataset: 0.8889\n",
            "\tnaive_bayes\n",
            "\t\tPerforming grid search\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "\t\tBest Parameters: {'var_smoothing': 1e-06}\n",
            "\t\tPerforming final cross validation\n",
            "\t\t0.9571428571428571 +/- 0.04738035414793428\n",
            "\t\tTraining Best Model on Full Training Set\n",
            "\t\tMaking final predictions on the full dataset\n",
            "\t\tFinal Accuracy on Full Dataset: 1.0000\n",
            "\tknn\n",
            "\t\tPerforming grid search\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "\t\tBest Parameters: {'metric': 'euclidean', 'n_neighbors': 3, 'weights': 'distance'}\n",
            "\t\tPerforming final cross validation\n",
            "\t\t0.6828571428571428 +/- 0.08011329845643081\n",
            "\t\tTraining Best Model on Full Training Set\n",
            "\t\tMaking final predictions on the full dataset\n",
            "\t\tFinal Accuracy on Full Dataset: 0.8056\n",
            "\trandom_forest\n",
            "\t\tPerforming grid search\n",
            "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
            "\t\tBest Parameters: {'max_features': 4, 'n_estimators': 450}\n",
            "\t\tPerforming final cross validation\n",
            "\t\t0.4014285714285714 +/- 0.030937725468153866\n",
            "\t\tTraining Best Model on Full Training Set\n",
            "\t\tMaking final predictions on the full dataset\n",
            "\t\tFinal Accuracy on Full Dataset: 0.3889\n",
            "\thyper\n",
            "\t\tSkipping Grid Search for HyperParamClassifier\n",
            "\t\t0.718095238095238 +/- 0.08485815829652713\n",
            "\t\tFitting with HyperParamClassifier\n",
            "\t\tTesting HyperParamClassifier on test set\n",
            "\t\tFinal Accuracy on Full Dataset: 0.8333\n",
            "Iris\n",
            "\tdecision_tree\n",
            "\t\tPerforming grid search\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "\t\tBest Parameters: {'criterion': 'entropy', 'max_depth': 12, 'min_samples_split': 50}\n",
            "\t\tPerforming final cross validation\n",
            "\t\t0.8999999999999998 +/- 0.097182531580755\n",
            "\t\tTraining Best Model on Full Training Set\n",
            "\t\tMaking final predictions on the full dataset\n",
            "\t\tFinal Accuracy on Full Dataset: 0.9667\n",
            "\tnaive_bayes\n",
            "\t\tPerforming grid search\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "\t\tBest Parameters: {'var_smoothing': 1e-06}\n",
            "\t\tPerforming final cross validation\n",
            "\t\t0.9416666666666667 +/- 0.07500000000000001\n",
            "\t\tTraining Best Model on Full Training Set\n",
            "\t\tMaking final predictions on the full dataset\n",
            "\t\tFinal Accuracy on Full Dataset: 1.0000\n",
            "\tknn\n",
            "\t\tPerforming grid search\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "\t\tBest Parameters: {'metric': 'euclidean', 'n_neighbors': 3, 'weights': 'distance'}\n",
            "\t\tPerforming final cross validation\n",
            "\t\t0.95 +/- 0.06666666666666667\n",
            "\t\tTraining Best Model on Full Training Set\n",
            "\t\tMaking final predictions on the full dataset\n",
            "\t\tFinal Accuracy on Full Dataset: 1.0000\n",
            "\trandom_forest\n",
            "\t\tPerforming grid search\n",
            "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
            "\t\tBest Parameters: {'max_features': 8, 'n_estimators': 450}\n",
            "\t\tPerforming final cross validation\n",
            "\t\t0.325 +/- 0.024999999999999994\n",
            "\t\tTraining Best Model on Full Training Set\n",
            "\t\tMaking final predictions on the full dataset\n",
            "\t\tFinal Accuracy on Full Dataset: 0.3000\n",
            "\thyper\n",
            "\t\tSkipping Grid Search for HyperParamClassifier\n",
            "\t\t0.9416666666666667 +/- 0.06508541396588878\n",
            "\t\tFitting with HyperParamClassifier\n",
            "\t\tTesting HyperParamClassifier on test set\n",
            "\t\tFinal Accuracy on Full Dataset: 1.0000\n",
            "Forest Cover Type\n",
            "\tdecision_tree\n",
            "\t\tPerforming grid search\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=10.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t\tBest Parameters: {'criterion': 'entropy', 'max_depth': 12, 'min_samples_split': 50}\n",
            "\t\tPerforming final cross validation\n",
            "\t\t0.665625 +/- 0.03165364315525149\n",
            "\t\tTraining Best Model on Full Training Set\n",
            "\t\tMaking final predictions on the full dataset\n",
            "\t\tFinal Accuracy on Full Dataset: 0.7000\n",
            "\tnaive_bayes\n",
            "\t\tPerforming grid search\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "\t\tBest Parameters: {'var_smoothing': 1e-06}\n",
            "\t\tPerforming final cross validation\n",
            "\t\t0.64375 +/- 0.030490777294126158\n",
            "\t\tTraining Best Model on Full Training Set\n",
            "\t\tMaking final predictions on the full dataset\n",
            "\t\tFinal Accuracy on Full Dataset: 0.6525\n",
            "\tknn\n",
            "\t\tPerforming grid search\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "\t\tBest Parameters: {'metric': 'euclidean', 'n_neighbors': 3, 'weights': 'distance'}\n",
            "\t\tPerforming final cross validation\n",
            "\t\t0.668125 +/- 0.01821100285541684\n",
            "\t\tTraining Best Model on Full Training Set\n",
            "\t\tMaking final predictions on the full dataset\n",
            "\t\tFinal Accuracy on Full Dataset: 0.6325\n",
            "\trandom_forest\n",
            "\t\tPerforming grid search\n",
            "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=10.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=10.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t\tBest Parameters: {'max_features': 4, 'n_estimators': 450}\n",
            "\t\tPerforming final cross validation\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=10.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t\t0.689375 +/- 0.03666252344015618\n",
            "\t\tTraining Best Model on Full Training Set\n",
            "\t\tMaking final predictions on the full dataset\n",
            "\t\tFinal Accuracy on Full Dataset: 0.6575\n",
            "\thyper\n",
            "\t\tSkipping Grid Search for HyperParamClassifier\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=10.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t\t0.67125 +/- 0.016105123408406394\n",
            "\t\tFitting with HyperParamClassifier\n",
            "\t\tTesting HyperParamClassifier on test set\n",
            "\t\tFinal Accuracy on Full Dataset: 0.6525\n"
          ]
        }
      ],
      "source": [
        "data_model_evaluation_results = dict()\n",
        "data_sampling_rate = 1.0  # Set to 1.0 to use the full dataset\n",
        "grid_search_cv_folds = 5  # You might want to adjust this based on your computational resources\n",
        "final_cv_folds = 10  # You might want to adjust this based on your computational resources\n",
        "\n",
        "for dataset_name in datasets:\n",
        "\n",
        "    print(dataset_name)\n",
        "\n",
        "    dataset_details = datasets[dataset_name]\n",
        "\n",
        "    target_feature = dataset_details[\"target_feature\"]\n",
        "    num_classes = dataset_details[\"num_classes\"]\n",
        "    classes = dataset_details[\"classes\"]\n",
        "\n",
        "    # Load data directly from the dataset dictionary\n",
        "    dataset = datasets[dataset_name]  # Already loaded dataset\n",
        "    X = dataset[\"data\"]  # Features\n",
        "    y = dataset[\"target\"]  # Labels\n",
        "    y = np.array(y)  #  Ensure `y` is a NumPy array\n",
        "    if np.isnan(y).any():\n",
        "        print(f\"\\tDataset '{dataset_name}' contains NaN values in the target variable '{target_feature}'.\")\n",
        "\n",
        "    #downsampling forest\n",
        "    if dataset_name == \"Forest Cover Type\":\n",
        "        sample_size = min(2000, int(len(X) * data_sampling_rate))  # Limit max 2000\n",
        "        X = X[:sample_size]\n",
        "        y = y[:sample_size]\n",
        "\n",
        "    #  Split into Train (80%) and Test (20%)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "    y_train = np.array(y_train)  #  Ensure NumPy array\n",
        "    y_test = np.array(y_test)\n",
        "\n",
        "\n",
        "    model_evaluation_results = dict()\n",
        "\n",
        "    for model_name in modelsBench:\n",
        "\n",
        "        print(\"\\t{}\".format(model_name))\n",
        "\n",
        "        model_details = modelsBench[model_name]\n",
        "        evaluation_results = dict()\n",
        "\n",
        "        if model_name == 'hyper':\n",
        "            #  Skip grid search, directly perform cross-validation\n",
        "            print(\"\\t\\tSkipping Grid Search for HyperParamClassifier\")\n",
        "\n",
        "            best_model = model_details['base_model']  # Directly use the base model\n",
        "            #crossvalidation\n",
        "            cv_results = sklearn.model_selection.cross_validate(best_model, X_train, y_train, cv=final_cv_folds)\n",
        "            print(\"\\t\\t{} +/- {}\".format(cv_results['test_score'].mean(), cv_results['test_score'].std()))\n",
        "\n",
        "            #Store cross-validation results\n",
        "            evaluation_results['final_cv_results'] = cv_results\n",
        "            evaluation_results['final_cv_mean'] = cv_results['test_score'].mean()\n",
        "            evaluation_results['final_cv_std_dev'] = cv_results['test_score'].std()\n",
        "\n",
        "            # fit on full training set\n",
        "            print(\"\\t\\tFitting with HyperParamClassifier\")\n",
        "            best_model.fit(X_train, y_train)\n",
        "\n",
        "            #test on test set\n",
        "            print(\"\\t\\tTesting HyperParamClassifier on test set\")\n",
        "            y_pred = best_model.predict(X_test)\n",
        "\n",
        "            # Compute Accuracy\n",
        "            accuracy = accuracy_score(y_test, y_pred)\n",
        "            print(f\"\\t\\tFinal Accuracy on Full Dataset: {accuracy:.4f}\")\n",
        "\n",
        "            #  Store predictions & accuracy\n",
        "            evaluation_results['final_predictions'] = y_pred\n",
        "            evaluation_results['final_accuracy'] = accuracy\n",
        "\n",
        "        else:\n",
        "            print('\\t\\tPerforming grid search')\n",
        "            grid_search_results = sklearn.model_selection.GridSearchCV(model_details['base_model'],\n",
        "                                                                   model_details['param_grid'],\n",
        "                                                                   cv=grid_search_cv_folds, verbose = 1,\n",
        "                                                                   n_jobs = 1)\n",
        "            grid_search_results.fit(X_train, y_train)\n",
        "            print(\"\\t\\tBest Parameters: {}\".format(grid_search_results.best_params_))\n",
        "\n",
        "            # Store the grid search results\n",
        "            evaluation_results['best_params'] = grid_search_results.best_params_\n",
        "            evaluation_results['best_score'] = grid_search_results.best_score_\n",
        "            evaluation_results['cv_results'] = grid_search_results.cv_results_\n",
        "\n",
        "            # Perform final cross validation\n",
        "            print('\\t\\tPerforming final cross validation')\n",
        "            best_model = grid_search_results.best_estimator_\n",
        "            cv_results = sklearn.model_selection.cross_validate(best_model, X_train, y_train, cv=final_cv_folds)\n",
        "            print(\"\\t\\t{} +/- {}\".format(cv_results['test_score'].mean(), cv_results['test_score'].std()))\n",
        "\n",
        "            # Store the cross validation results\n",
        "            evaluation_results['final_cv_results'] = cv_results\n",
        "            evaluation_results['final_cv_mean'] = cv_results['test_score'].mean()\n",
        "            evaluation_results['final_cv_std_dev'] = cv_results['test_score'].std()\n",
        "\n",
        "            # Train Best Model on Full Training Set\n",
        "            print(\"\\t\\tTraining Best Model on Full Training Set\")\n",
        "            best_model.fit(X_train, y_train)\n",
        "\n",
        "            # Test Best Model on Full Test Set\n",
        "            print('\\t\\tMaking final predictions on the full dataset')\n",
        "            y_pred = best_model.predict(X_test)\n",
        "\n",
        "            #  Compute Accuracy\n",
        "            accuracy = accuracy_score(y_test, y_pred)\n",
        "            print(f\"\\t\\tFinal Accuracy on Full Dataset: {accuracy:.4f}\")\n",
        "\n",
        "            #  Store predictions & accuracy\n",
        "            evaluation_results['final_predictions'] = y_pred\n",
        "            evaluation_results['final_accuracy'] = accuracy\n",
        "\n",
        "\n",
        "             # Add all evaluation details to the evaluation dictionary\n",
        "        model_evaluation_results[model_name] = evaluation_results\n",
        "\n",
        "\n",
        "    with open('evaluation_results_' + time.strftime(\"%Y%m%d_%H%M%S\") + '.data', 'wb') as f:\n",
        "      pickle.dump(model_evaluation_results, f)\n",
        "    data_model_evaluation_results[dataset_name] = model_evaluation_results\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PAjdyMyzUnNS"
      },
      "source": [
        "### Experiment Results Summary\n",
        "Present a series of tables and graphs illustraitng experiment results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yPUjZxozUnNS",
        "outputId": "751e2b24-850a-4c4a-a331-ed9d3e251bbe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   decision_tree  naive_bayes       knn  random_forest  \\\n",
            "Index                                                                    \n",
            "Breast Cancer           0.912281     0.956140  0.938596       0.956140   \n",
            "Digits                  0.830556     0.891667  0.983333       0.905556   \n",
            "Wine                    0.888889     1.000000  0.805556       0.388889   \n",
            "Iris                    0.966667     1.000000  1.000000       0.300000   \n",
            "Forest Cover Type       0.700000     0.652500  0.632500       0.657500   \n",
            "\n",
            "                      hyper  \n",
            "Index                        \n",
            "Breast Cancer      0.956140  \n",
            "Digits             0.983333  \n",
            "Wine               0.833333  \n",
            "Iris               1.000000  \n",
            "Forest Cover Type  0.652500  \n"
          ]
        }
      ],
      "source": [
        "data = []\n",
        "for row_key, sub_dict in data_model_evaluation_results.items():\n",
        "    row_data = {\"Index\": row_key}\n",
        "    for col_key, inner_dict in sub_dict.items():\n",
        "        row_data[col_key] = inner_dict.get('final_accuracy', None)  # Extract the specific value\n",
        "    data.append(row_data)\n",
        "results_df = pd.DataFrame(data).set_index(\"Index\")\n",
        "print(results_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ranks_df = results_df.rank(method=\"min\", ascending=False, axis = 1)\n",
        "print(ranks_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXVUUqdlhE6x",
        "outputId": "2f584e20-a3e8-4468-bcd9-b792a30708df"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   decision_tree  naive_bayes  knn  random_forest  hyper\n",
            "Index                                                                   \n",
            "Breast Cancer                5.0          1.0  4.0            1.0    1.0\n",
            "Digits                       5.0          4.0  1.0            3.0    1.0\n",
            "Wine                         2.0          1.0  4.0            5.0    3.0\n",
            "Iris                         4.0          1.0  1.0            5.0    1.0\n",
            "Forest Cover Type            1.0          3.0  5.0            2.0    3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "aeon.benchmarking.stats.check_friedman(ranks_df.values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D64Ny1HFhG5G",
        "outputId": "0137d6cd-0711-41b9-9e7c-70656f91a439"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "avg_ranks = np.mean(ranks_df, axis=0)\n",
        "print(avg_ranks)\n",
        "aeon.benchmarking.stats.nemenyi_test(avg_ranks, len(avg_ranks), 0.05)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JWBEPlifhJ_B",
        "outputId": "5c5ae343-c4db-4f65-ae11-029cdc1066d1"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "decision_tree    3.4\n",
            "naive_bayes      2.0\n",
            "knn              3.0\n",
            "random_forest    3.2\n",
            "hyper            1.8\n",
            "dtype: float64\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ True, False, False, False, False],\n",
              "       [ True,  True,  True,  True, False],\n",
              "       [ True, False,  True,  True, False],\n",
              "       [ True, False, False,  True, False],\n",
              "       [ True,  True,  True,  True,  True]])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ranks_df.index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9v75Ck3ghMI0",
        "outputId": "7ead0329-87f7-4791-f72c-81be837cbff6"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Breast Cancer', 'Digits', 'Wine', 'Iris', 'Forest Cover Type'], dtype='object', name='Index')"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "aeon.visualisation.plot_critical_difference(ranks_df.values,\n",
        "                                            ranks_df.columns,\n",
        "                                            test=\"Nemenyi\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        },
        "id": "z2NXLMuehOJ1",
        "outputId": "0bd08ef2-416d-4cb1-8e3c-e077d33a4d40"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x240 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COHecVeiUnNS"
      },
      "source": [
        "## Task 4: Reflection\n",
        "A short (less than 400 words) reflection on the results of the experiment and the experience of running it.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHk4d3FQUnNS"
      },
      "source": [
        "The goal of this assignment is to create and evaluate the performance of our ensemble KNN classifier (HyperParamEnsemble) against four traditional models: Decision Tree, Naive Bayes, KNN, and Random Forest.\n",
        "\n",
        "I have used only light and numerical datasets already available in the Scikit-Learn library to reduce computational load on my budget PC.\n",
        "\n",
        "From the results obtained after defining my HyperParamEnsembleClassifier as an ensemble of KNNs (with n_estimators set to 3), where each KNN was initialized with a random combination of parameters from the following grid:\n",
        "\n",
        "param_grid = {\n",
        "    'n_neighbors': list(range(3, 6, 2)),  \n",
        "    'weights': ['distance'],  \n",
        "    'metric': ['euclidean', 'manhattan']  \n",
        "}\n",
        "We can clearly see that our ensemble was the best-performing model compared to the other classifiers, achieving an accuracy of around 0.65 for large datasets and 1.00 for smaller datasets.\n",
        "\n",
        "Itâ€™s important to note that the other models also used the best possible hyperparameters. Although a full grid search was not performed for all models (to alleviate computational load), the chosen hyperparameters were based on previous assignments (Task 2) and are expected to be the optimal settings for each model. Even with optimized parameters, none of the models were able to outperform our KNN ensemble.\n",
        "\n",
        "The worst-performing model was Decision Tree, possibly because this model performs better with categorical data. However, Naive Bayes outperformed our HyperParamEnsemble on the Wine dataset. This suggests that certain models may be better suited for specific data structures. Additionally, Random Forest performed unexpectedly poorly on the Wine and Iris datasets, possibly due to limitations in feature selection or overfitting.\n",
        "\n",
        "While the HyperParamEnsemble showed strong performance, this study was limited to only five datasets, meaning the results may not generalize to larger, more complex datasets. Future work could explore other ensembling techniques, such as stacking or boosting, and compare different base models beyond KNN."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}